---
title: "Séries chronologiques Projet 2022"
author: "Matthias Lang, Valentin De Crespin De Billy"
date: "Janvier 30, 2022"
output:
  html_document: null
  pdf_document: default
  df_print: paged
subtitle: Groupe 16, Sujet 11
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(latex2exp) # pour "TeX("$\\alpha$")
library(stargazer)
library(dplyr)
library(astsa)
library(changepoint)
#library(caschrono) -> pas possible, dépendance de r-foreign -> R 3.6
library(tseries)
library(forecast)
library(lmtest)

wd <- "/home/matthias/Documents/Wien/Statistik/Erasmus/cours/serieschrono/projet/"
setwd(wd)
```

## Les bases

Dans ce projet il faut effectuer une analyse des données reçues, et faire une prévision pour l'année 1971.
Nous allons utiliser R avec les packages `tseries` et `astsa`.

Premièrement, il suit une analyse rudimentaire des données et de leurs propriétés.

![](Sujet11.jpeg)
```{r import, include=FALSE}
donnees <- read.csv("donnees.csv", stringsAsFactors=FALSE)
donnees$date = as.Date(donnees$date, "%d/%m/%Y")
miles = ts(donnees$miles, 
           start=as.double(format.Date(donnees$date[1], "%Y")), 
           frequency=12)
```
Les données sont affichées ci-dessous. C'est bien évident qu'il ne s'agit pas d'une séries stationnaire, car il y a une tendance.
Denommons les miles par mois avec la suite $(X_t)$.
```{r representation graphique de la serie temporelle}
plot(donnees, type="l", main = "U.K. airlines: aircraft miles flown, by months (thousands)")
#plot(donnees$date, log(donnees$miles), type = "l")
```
L'examen du graphique montre une tendance croissante, il paraît peut-être même une croissance exponentielle.
Le dernier cas a lieu si la variance croit avec la tendance.
C'est vraisemblable qu'il a aussi une saisonnalité annuelle, c'est à dire de période 12 car les données sont mensuelles.
Eux peuvent être prises compte par l'introduction d'une polynôme de retard $B^{12}$.


**En fait on voit que les données sont stationnaires? Comment est-ce possible : **
```{r}
adf.test(donnees$miles, alternative = "stationary")
```
#### Transformation

Mais il semble aussi qu'il ait une croissance exponentielle. Cela ne surprend pas avec une scale non-négative.
Pour comparison: La variance de la première moitié est $`r round(var(head(miles,length(miles)/2)), -5)`$, la seconde moitié $`r round(var(tail(miles,length(miles)/2)), -5)`$.
Afin de reducer cette propriété nous prenons le logarithme népérien (variances: $`r round(var(head(log(miles),length(miles)/2)), 3)`$ et $`r round(var(tail(log(miles),length(miles)/2)), 3)`$).

```{r}
plot(donnees$date, log(miles), type= "l",
     xlab = "date",
     ylab = TeX("$\\log(X_t)$"),
     main = TeX("$\\log(X_t)$"))
```


```{r}
dw = dwtest(log(miles) ~ date, 
            data = donnees)$p.value
```
On a fait un Durbin-Watson Test: $H_0$ afin de savoir si l'autocorrelation des erreurs estimées d'un modèle linéare `log(miles) ~ date` est égal à 0, qui est rejetée avec une valeur p de $`r round(dw, 3)`$. 
Clairement on rejète $H_0$.
Il y aura sûrement des autres assumptions blessées pour faire un GLM, par exemple l'égalité des variances et l'indépandence des valeurs et des erreurs.

### La tendance

En gros, on a deux possibilités pour supprimer la tendance et faire en sorte que $\mathbb{E}[X_t] = 0$, soustraire une tendance ou différencier d'un ordre quelquonque.

##### traiter de la tendance en mode additive

Soit avec un modèl additif:

```{r eval=FALSE, include=FALSE}
#m = decompose(log(miles), type = "additive")
#plot(m)
# plot(decompose(miles, type = "multiplicative")) -> I think multiplicative is more fitting, as the lag and seasonality for the non-log at least are increasing with time
```
```{r tendance linéare additive}
fit.add = lm(log(miles) ~ date, data = donnees)

par(mfrow=c(1,2))
plot(donnees$date, log(miles), 
     ylab = TeX("$\\log(X_t)$"),
     xlab = "date",
     type = "l")
abline(fit.add, col = "red")

legend("bottomright",
       legend=c("Série observée",
                "Régression"), 
       col = c("black",
               "red"),
       lty = 1,
       lwd = 2,
       cex = 0.7,
       text.col = "slategray4",
       #title = "Années",
       border = "white")

# legend(legend="regression",
#        x=-2,y=8.85,xjust=1,bty="n",
#        fill = "red")

plot(fit.add$residuals,
     xlab = "date",
     type = "l")
```

Ici un problème se présente:
```{r echo=FALSE}
par(mar = c(3,4,4,2))
acf(fit.add$residuals)
```
L'autocorrélation ne decroit pas.

##### traiter de la tendance en différenciant

Soit en différencier:
$$log(X_t) - log(X_{t-1}) = (1-B)\log(X_t)$$
```{r delta}
mdiff1 = diff(log(miles), lag = 1, difference = 1) #12
# difference to the first order

fit.mult = lm(mdiff1 ~ tail( donnees$date, length(mdiff1) ))

par(mfrow=c(1,2))
plot(tail(donnees$date, length(mdiff1)), 
     mdiff1, type = "l",
     ylab = TeX("$(1-B)\\log(X_t)$"),
     xlab = "date")
abline(fit.mult, col = "red")
plot(fit.mult$residuals, 
     xlab = "date",
     type = "l")
```
Il ne reste pas une tendence. Ci-dessous on voit que il n'y a ni une tendance ni une moyenne qui n'est pas zéro. 
```{r}
summary(fit.mult)$coefficients
```
Laquelle mèthode choisir ? Généralment différencier est mieux.

Est-ce qu'il vaut différencie encore une fois ? On va comparer la variance de la série une fois différenciée, $\widehat{Var}((1-B)\log X_t = `r round(var(mdiff1), 3)`$ avec la série deux fois différencie, $\widehat{Var}((1-B)^2\log X_t = `r round(var(diff(mdiff1, lag = 1, difference = 1)), 3)`$ ($\widehat{Var}(\log X_t = `r round(var(log(miles)), 3)`$).
Car on a déjà trouvé que la tendance a disparu, et on voit en plus que différencier en supplémentaire fait augmenter la variance, il ne vaut pas encore différencier.

La séries est-elle stationnaire ? Non, il y a encore la saisonalité.
```{r eval=FALSE, include=FALSE}
# Est-ce que cela peut aider à decider entre le modèle additif et multiplicatif ?

par(mfcol=c(2,2),mar=c(2,4,1,5),pch=20)

acf(fit.add$residuals); mtext("  add.",3,las=1)
pacf(fit.add$residuals)
acf(fit.mult$residuals); mtext("  mult.",3,las=1)
pacf(fit.mult$residuals)
```


### Saisonnalité

On introduit une componente saisonnal dans le modèl proposé.

$$(1-B)(1-B^{12}) \log(X_t) $$
```{r test pour station.}
mdiff12diff1 = diff(mdiff1, lag=12, differences=1)
#tsdisplay(mdiff12diff1, ci.type = "ma", main = "(1-B)(1-B^12)X_t")
plot(tail(donnees$date, length(mdiff12diff1)), 
     mdiff12diff1, 
     type = "l",
     ylab = TeX("$(1-B)(1-B^{12}) \\log(X_t)$"),
     xlab = "date")
points(tail(donnees$date, length(mdiff12diff1)), 
     mdiff12diff1)
abline(h=0, col = "grey")
```

Pour tester si la série est stationnaire nous utilisons l'Augmented Dickey-Fuller t-statistic test. 
ADF test is a test to check whether the series has a unit root or not. If it exists, the series has a linear trend. However, if it’s not, we can say that the model is stationary.

```{r}
adf.test(mdiff12diff1)
```

Est-ce qu'il vaut différencie encore une fois ? On va comparer la variance de la série une fois différenciée et de-saisonnalisé, $\widehat{Var}((1-B)(1-B^{12}\log X_t = `r round(var(mdiff12diff1), 3)`$ avec la série deux fois de-saisonnalisé, $\widehat{Var}( (1-B)(1-B^{12})^2\log X_t ) = `r round(var(diff(mdiff12diff1, lag = 12)), 3)`$.
Comme encore plus différencier ne fait pas baisser la variance, et comme on verra que la série est déjà stationnaire, on ne différenci plus. **stationnaire aussi de 2nd ordre si pour $\forall t \in \mathbb{Z}$:$\mathbb{E}(X_t^2) < \infty$$, $\mathbb{E}(X_t) = m$ et $\forall h \in \mathbb{Z} cov(X_t, X_{t+h} = \gamma(h)$**

Peut-on déjà poser que $(1-B)(1-B^{12}) \log(X_t) = \varepsilon_t$, avec $\varepsilon_t$ un bruit blanc ?

```{r echo=FALSE}
par(mfrow=c(1,2), mar=c(3,4,1,1))
acf(mdiff12diff1, lag.max = 30, ci.type = "ma")
pacf(mdiff12diff1, lag.max = 30)
```
=> MA(2,12) , cela explique aussi p(12-2) = p(10) (?) et la décroissement lente de pacf, la forme la fonction d'autocorrélation partielle estimée confirme qu'il peut bien s'agèrer d'un processus du moyenne mobile.

*Ici on peut éxpliquer qu'est-ce que c'est, l'ACF.*
En ce qui concerne l'ACF:
Ils sortent des bâtons significatives à 1, 2 et 12 mois, sans qu'on puisse détérminer une règle.
D'ailleurs il y n'a pas une décroissement lente, qui pourrait indiquer qu'on faut encore differencier.
Mais il n'y a aucune repère qu'il faut un modèl multiplicatif (des bâtons qui sortent encadré par des bâtons de signe inversée). 

En ce qui concerne les auto-corrélations partielles, il y a égalements des fréquences significatives pour un décalage de 1,2,4, 10, 11 et 12 mois, et cela ne se abbaisse pas avec un lag plus grand semble-t-il.
Cela indique qu'il faut un modèle MA !


Les $\varepsilon$ pour les deux modèls semblent stationnaire:

```{r delta 2.0, eval=FALSE, include=FALSE}
# Ca sert à quoi ?

adf.test(fit.mult$residuals, k=1)
adf.test(fit.mult$residuals, k=2)
adf.test(fit.mult$residuals, k=3)
adf.test(fit.mult$residuals, k=4)


adf.test(fit.add$residuals, k=1)
adf.test(fit.add$residuals, k=2)
adf.test(fit.add$residuals, k=3)
adf.test(fit.add$residuals, k=4)
```

### Modèliser

#### Modèle 1
Après la dernière différenciation on a vu que les données pourraient être modélisées par un MA(2) avec saisonalité.
Alors on aurait le modèle suivante, avec $\epsilon_t$ supposé b.b.: 

$$(1-B)(1-B^{12}) \log(X_t) = (1-\theta_1B-\theta_2B^2)(1-\theta_{12}B^{12})\epsilon_t$$
Autrement dit, une $\text{SARIMA}_{12}[(p= 0,d= 1,q= 2),(P= 0,D= 1,Q= 1)]$

```{r fitting a model}
sarima_12.012.011 <- arima(log(miles), order = c(0,1,2), seasonal=list(order = c(0,1,1), perdiod=12))
sarima_comparai <- arima(mdiff12diff1, order = c(0,0,2), seasonal=list(order = c(0,0,1), perdiod=12)) #devrait être le même ?
summary(sarima_12.012.011)
coeftest(sarima_12.012.011) #https://stackoverflow.com/questions/43826952/how-can-i-get-the-t-statistics-for-the-results-of-an-ar1-model-in-r
```


```{r echo=FALSE}
par(mfrow= c(1,2), mar=c(2,4,1,0.5),pch=20)
acf1 = acf(residuals(sarima_12.012.011), ci.type="ma", lag.max= 30)
pacf(residuals(sarima_12.012.011), main="corrélogramme partiel de residuals(model1)", lag.max= 30)

rho1 = round(acf1[1/12]$acf[1], 2)
rho2 = round(acf1[2/12]$acf[1], 2) # rho1 ^2 (??)
rho3 = round(acf1[3/12]$acf[1], 2) # # rho1^3 (??)
```

Il y a encore quelques bâtons qui sortens, notamment $r(3), r(12)$ et $r(19)$.
Dans le graphique "ACF", est-ce que $\rho(3)$ sort de l'intervalle de confiance ? Cela peut indiquer qu'il a encore une componente MA dans les erreurs. Pour répondre à cette question, on va faire le calcul.

Intervalle de Bartlett q=3 : 
      $$\pm \frac{1.96}{\sqrt{N}} (1 + 2\hat{\rho}^2(1) + 2\hat{\rho}^2(2) + 2\hat{\rho}^2(3))^{0.5} = 
        \pm \frac{1.96}{\sqrt{96}}(1 + 2*`r rho1^2`     +  2*`r rho2^2`    + 2*`r rho3^2`)^{0.5} = 
        \pm `r round(1.96/sqrt(96)*(1+ 2*rho1^2         + 2*rho2^2         + 2*rho3^2)^0.5, 3)` 
        > 
        \rho(3) = `r rho3`$$ 
        **faut il remplacer N par N-1-12 parce qu'on a différencié ?**

Alors on va ensuite, comme modèle 3, considerer un modèle avec une partie autoreggresive.


```{r model diagnostics}
# tsdiag(sarima_12.012.011)

# portmanteau tests
# Box.test(mdiff12diff1)
acf(residuals(sarima_12.012.011)) # pour montrer b.b. E(e_t*e_s) = 0
box = Box.test(residuals(sarima_12.012.011), type = "Ljung-Box")$p.value
```

P-value de Ljung-Box-Test des résidues : $`r box`$.

Après differencier et modèliser il faut tester s'il reste qu'un bruit blanc.
On peut utiliser un Box-Test.

### densité spectrale

##### Fréquences

Pour le moment je sais pas trop comment expliquer / utiliser.

```{r periodogramm, echo=FALSE}
periodogramm <- function(z){
  
# Abbildung 3
par(mfcol=c(3,1),mar=c(2,2,0.5,2),pch=20)
h <- 2*pi
H <- spec.pgram(z, taper=0,detrend=FALSE,fast=FALSE,plot=FALSE)
plot(h*H$freq,H$spec/h,type="l")
mtext(" (a)",4,las=1)

# tendance
t = tail(donnees$date,length(z))
H <- spec.pgram(lm(z ~ t)$residuals,taper=0,detrend=FALSE,fast=FALSE,plot=FALSE)
plot(h*H$freq,H$spec/h,type="l")
mtext(" (c)",4,las=1)

plot(log(h*H$freq[1:20]),log(H$spec[1:20]/h),type="o",lwd=2)  
mtext(" (e)",4,las=1) 

for (c in (-15):(15)) abline(a=c,b=-1,col="gray")
}

#periodogramm(mdiff12diff1)
periodogramm(fit.add$residuals)
periodogramm(sarima_12.012.011$residuals)
periodogramm(miles)
```


C'est déja mieux, les erreurs semblent plus stable, mais pourtant il existe une autocorrélation.

```{r}
periodogramm(mdiff1)
```

Pour les données différenciées il n'y a pas une courbe raide vers le zéro (voir a, fréquence de Fourier $\omega_k = \frac{2\pi k}{n}$)).
En outre, le log-périodogrammes des résidus tombe moins vite pour les résidus des données différenciées (voir e) qu'implique des résidues stationnairs.

Steigt die Spektraldichte $f(\omega)$ mindestens so steil an wie $h(\omega ) = c\omega^{-1}$ , dann ist sie nicht integrierbar, was unvereinbar ist mit Stationarität, weil die Varianz eines stationären Prozesses gegeben ist durch das Integral der Spektraldichte. In der Praxis ist $f$ unbekannt und muss durch einen Proxy ersetzt werden, z.B. durch das Periodogramm $I$. Für eine graphische Einschätzung der Stationarität kann man $I(\omega)$ gegen $\omega$ plotten und mit $h(\omega ) = c\omega^{-1}$ vergleichen. Einfacher ist es aber, wenn man $\log(I(\omega))$ gegen $\log(\omega)$ plottet und mit Geraden der Steigung -1 vergleicht (siehe Abbildung 3).



#### Modèle 2

Ici on peut également essayer de faire un modèle additif 
$$(1-B)(1-B^{12}) \log(X_t) = (1-\theta_1B-\theta_{12}B^{12})\epsilon_t$$,  
autrement dit $\text{SARIMA}_{12}[(p= 0,d= 1,q= 12),(P= 0,D= 1,Q= 0)]$.

#### Modèle 3

Pour le modèle 1 on a eu un graphique pour les autocorrélations suivants.

```{r}
pacf(residuals(sarima_12.012.011), main="corrélogramme partiel de residuals(model1)", lag.max= 30)
```

$$(1-B)(1-B^{12}) \log(X_t) = (1-\theta_1B-\theta_{12}B^{12})\epsilon_t$$,  

```{r model 3}
sarima_12.012.111 <- arima(log(miles), order = c(10,1,2), seasonal=list(order = c(0,1,1), perdiod=12))
# ar10 significativ, en plus pas de coefficients sign. !

summary(sarima_12.012.111)
coeftest(sarima_12.012.111) #https://stackoverflow.com/questions/43826952/how-can-i-get-the-t-statistics-for-the-results-of-an-ar1-model-in-r
pacf(residuals(sarima_12.012.111), main="corrélogramme partiel de residuals(model3)", lag.max= 60)
```
Ils ne sortens plus des bâtons, mais il faut calculer beaucoup de estimateurs de coéfficients.

#### Modèle 4

Plus parcimonieux que modèle 1, avec un MA(1):

```{r  model 4}
sarima_12.012.011 <- arima(log(miles), order = c(0,1,1), seasonal=list(order = c(0,1,1), perdiod=12))
sarima_comparai <- arima(mdiff12diff1, order = c(0,0,2), seasonal=list(order = c(0,0,1), perdiod=12)) #devrait être le même ?
summary(sarima_12.012.011)
coeftest(sarima_12.012.011) #https://stackoverflow.com/questions/43826952/how-can-i-get-the-t-statistics-for-the-results-of-an-ar1-model-in-r
```

```{r}
par(mfrow= c(1,2), mar=c(2,4,1,0.5),pch=20)
acf1 = acf(residuals(sarima_12.012.011), ci.type="ma", lag.max= 30)
pacf(residuals(sarima_12.012.011), main="corrélogramme partiel de residuals(model1)", lag.max= 30)
```
Dans le PACF ils sortent moins de bâtons que pour le modèle 1.


## Choix du modèle

### Base de test

Pour comparer les modèles qu'on a choisi pour faire la prévision, on sépare la dernière année, 1970. Puis on calcule les estimateurs pour les modèles avec tous les années antérieures et fait des prévisions pour l'année 1970.
La meilleure prévision détermine la modèle quelle on va choisir finalement.
Pour comparer la qualité des prévision on peut utiliser le MSE (mean squared error) et leurs AIC :
$\text{MSE} = \frac{1}{12}\sum_{t=Jan 1970}^{Dec 1970}(\hat{X_t} - X_t)^2$.


```{r}
# L'année 1970
miles.test =  tail(miles, 12)
# Les années 1963-1969
miles.train = head(miles, length(miles)-12)

# Puis MSE?
```

### Calcul des modèles avec la base de test

On estime les paramètres avec la base de donnée `miles.test` de largeur `r length(miles.test)` (largeur original `r length(miles)`.

```{r model avec miles.train}
model <- arima(log(miles.train), order = c(0,1,1), seasonal=list(order = c(0,1,1), perdiod=12))
miles.prev <- exp(forecast(model, 12)$mean)
model.mse = sum((miles.test - miles.prev)^2) / 12
model$aic

plot(miles.prev, col="blue",
     main = paste("AIC: ", model$aic),
     ylab = "miles")
lines(miles.test)
grid()

```

```{r}

# Arima # {forecast} <-> comparer avec astsa?
# https://developpaper.com/arma-arima-box-jenkins-sarima-and-arimax-models-in-r-language-are-used-to-predict-time-series-data/

# library: {astsa}

test = sarima(log(miles), 
              p= 0, d= 1, q= 0, P= 0, D= 0, Q= 0, S= 12,
              details = T) # => Plot et Diagnostics

# Values: fit, AIC, BIC, ttable

#sarima.for #=> pour la prévision
```
```{r}
# library {stats}
test2 = arima(log(miles), order = c(0,1,0), seasonal = list(order= c(0,0,0), period=12))
predict(test2, 12)
```



```{r eval=FALSE, include=FALSE}
#d'une vidéo Youtube
# pour afficher avec les intervalles de confiance

plot(Z)
lines(mydata.pred$pred)
lines(mydata.pred$se + 2* mydata.pred$se)
lines(mydata.pred$se - 2* mydata.pred$se)

```

### Comparaison et choix du modèle

Ci-dessous tous les modèles qu'on a trouvé sont comparés dans un tableau.
Le plus petits le MSE, le meilleur.
De la même manière avec les AICs, qui indiquent aussi si un modèle est parcimonieux. Ce critère repose donc sur un compromis entre la qualité de l'ajustement et la complexité du modèle, en pénalisant les modèles ayant un grand nombre de paramètres.

```{r placeholder}
sarima_12.001.011_AIC = 308
mse = 443203
```


| Model                                     | AIC                           | MSE         |
|-------------------------------------------|-------------------------------|-------------|
| $\text{SARIMA}_{12}[(0, 0, 1),(0, 1, 1)]$ | $`r sarima_12.001.011_AIC`$   | $`r mse`$   |
| $\text{SARIMA}_{12}[(0, 0, 1),(0, 1, 1)]$ | $`r sarima_12.001.011_AIC`$   | $`r mse`$   |
| $\text{SARIMA}_{12}[(0, 0, 1),(0, 1, 1)]$ | $`r sarima_12.001.011_AIC`$   | $`r mse`$   |
| $\text{SARIMA}_{12}[(0, 0, 1),(0, 1, 1)]$ | $`r sarima_12.001.011_AIC`$   | $`r mse`$   |


## Prévision pour l'année 1971

```{r forecast}
model1 <- arima(log(miles), order = c(0,1,1), seasonal=list(order = c(0,1,1), perdiod=12))
fvalues <- forecast(model1, 12)
# = fvalues2 <- predict(model1, 12)
print(fvalues)
plot(fvalues, col.main = "red")
plot(forecast(sarima_12.012.011,12))
```

> Tu déconnes avec tes tonnes de projets

> Ils vont encore s’entasser avec ceux de l’année prochaine

> Viens, j’ai fait le plein de patience

> Y a assez d’essence pour rouler jusqu’à l’horizon
